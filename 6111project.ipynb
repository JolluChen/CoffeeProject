{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.2.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the data:\n",
      "     Day Unnamed: 1  Cappuccino Sales  Latte Sales  Mocha Sales  Promotion Day\n",
      "0  Day 1     Sunday              52.0         48.0         68.0              0\n",
      "1  Day 2     Monday              40.0         70.0         40.0              0\n",
      "2  Day 3    Tuesday              45.0         41.0         41.0              0\n",
      "3  Day 4  Wednesday              56.0         58.0         57.0              0\n",
      "4  Day 5   Thursday             106.0         88.0        112.0              1\n",
      "\n",
      "--------------------\n",
      "\n",
      "Dataframe Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Day               22 non-null     object \n",
      " 1   Unnamed: 1        22 non-null     object \n",
      " 2   Cappuccino Sales  15 non-null     float64\n",
      " 3   Latte Sales       15 non-null     float64\n",
      " 4   Mocha Sales       15 non-null     float64\n",
      " 5   Promotion Day     22 non-null     int64  \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 1.2+ KB\n",
      "\n",
      "--------------------\n",
      "\n",
      "Missing values per column:\n",
      "Day                 0\n",
      "Unnamed: 1          0\n",
      "Cappuccino Sales    7\n",
      "Latte Sales         7\n",
      "Mocha Sales         7\n",
      "Promotion Day       0\n",
      "dtype: int64\n",
      "\n",
      "--------------------\n",
      "\n",
      "Descriptive Statistics:\n",
      "          Day Unnamed: 1  Cappuccino Sales  Latte Sales  Mocha Sales  \\\n",
      "count      22         22         15.000000    15.000000    15.000000   \n",
      "unique     22          7               NaN          NaN          NaN   \n",
      "top     Day 1     Sunday               NaN          NaN          NaN   \n",
      "freq        1          4               NaN          NaN          NaN   \n",
      "mean      NaN        NaN         82.533333    84.000000    94.733333   \n",
      "std       NaN        NaN         34.551962    34.153017    44.793920   \n",
      "min       NaN        NaN         40.000000    41.000000    40.000000   \n",
      "25%       NaN        NaN         53.500000    56.500000    58.500000   \n",
      "50%       NaN        NaN         75.000000    85.000000    80.000000   \n",
      "75%       NaN        NaN        112.000000   105.500000   131.500000   \n",
      "max       NaN        NaN        140.000000   145.000000   170.000000   \n",
      "\n",
      "        Promotion Day  \n",
      "count       22.000000  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean         0.136364  \n",
      "std          0.351250  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.000000  \n",
      "75%          0.000000  \n",
      "max          1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the demand history data\n",
    "# Make sure 'demand_history.xlsx' is in the same directory as your notebook,\n",
    "# or provide the full path.\n",
    "try:\n",
    "    df = pd.read_excel('demand_history.xlsx')\n",
    "\n",
    "    # Display the first few rows to understand the structure\n",
    "    print(\"First 5 rows of the data:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n--------------------\\n\")\n",
    "\n",
    "    # Get some basic info about the data (columns, data types, non-null counts)\n",
    "    print(\"Dataframe Info:\")\n",
    "    df.info()\n",
    "    print(\"\\n--------------------\\n\")\n",
    "\n",
    "    # Check for missing values per column\n",
    "    print(\"Missing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n--------------------\\n\")\n",
    "\n",
    "    # Get basic descriptive statistics\n",
    "    print(\"Descriptive Statistics:\")\n",
    "    print(df.describe(include='all')) # Use include='all' to see stats for non-numeric columns too\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'demand_history.xlsx' not found. Please make sure the file is in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sales values in training data after numeric conversion:\n",
      "Cappuccino Sales    0\n",
      "Latte Sales         0\n",
      "Mocha Sales         0\n",
      "dtype: int64\n",
      "\n",
      "Shapes of training features and target variables:\n",
      "X_train_encoded: (15, 7)\n",
      "y_train_cap: (15,)\n",
      "y_train_lat: (15,)\n",
      "y_train_moc: (15,)\n",
      "\n",
      "Shape of features for the prediction week:\n",
      "X_pred_encoded: (7, 7)\n",
      "\n",
      "Training Features (X_train_encoded) Head:\n",
      "   Promotion Day  DayOfWeek_Monday  DayOfWeek_Saturday  DayOfWeek_Sunday  \\\n",
      "0              0             False               False              True   \n",
      "1              0              True               False             False   \n",
      "2              0             False               False             False   \n",
      "3              0             False               False             False   \n",
      "4              1             False               False             False   \n",
      "\n",
      "   DayOfWeek_Thursday  DayOfWeek_Tuesday  DayOfWeek_Wednesday  \n",
      "0               False              False                False  \n",
      "1               False              False                False  \n",
      "2               False               True                False  \n",
      "3               False              False                 True  \n",
      "4                True              False                False  \n",
      "\n",
      "Prediction Features (X_pred_encoded) Head:\n",
      "    Promotion Day  DayOfWeek_Monday  DayOfWeek_Saturday  DayOfWeek_Sunday  \\\n",
      "15              0              True               False             False   \n",
      "16              0             False               False             False   \n",
      "17              0             False               False             False   \n",
      "18              1             False               False             False   \n",
      "19              0             False               False             False   \n",
      "\n",
      "    DayOfWeek_Thursday  DayOfWeek_Tuesday  DayOfWeek_Wednesday  \n",
      "15               False              False                False  \n",
      "16               False               True                False  \n",
      "17               False              False                 True  \n",
      "18                True              False                False  \n",
      "19               False              False                False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor # Added RandomForest as another option\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame loaded previously\n",
    "\n",
    "# 1. Clean Column Names and Data Types\n",
    "df = df.rename(columns={'Unnamed: 1': 'DayOfWeek'})\n",
    "\n",
    "# 2. Separate known data (Days 1-15) and the week to predict (Days 16-22)\n",
    "train_df = df.iloc[:15].copy()\n",
    "predict_df_features = df.iloc[15:].copy() # Features for the week we want to predict\n",
    "\n",
    "# Ensure sales columns are numeric, handling potential errors\n",
    "sales_cols = ['Cappuccino Sales', 'Latte Sales', 'Mocha Sales']\n",
    "for col in sales_cols:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "\n",
    "# Check if any sales data became NaN after conversion (shouldn't if input was okay)\n",
    "print(\"Missing sales values in training data after numeric conversion:\")\n",
    "print(train_df[sales_cols].isnull().sum())\n",
    "# Handle potential NaNs if they appeared (e.g., fill with median or mean)\n",
    "# train_df = train_df.fillna(train_df.median(numeric_only=True)) # Example: fill with median\n",
    "\n",
    "# 3. Feature Engineering: One-Hot Encode DayOfWeek\n",
    "# We need to encode for both training and prediction sets consistently\n",
    "combined_df = pd.concat([train_df[['DayOfWeek', 'Promotion Day']], predict_df_features[['DayOfWeek', 'Promotion Day']]], ignore_index=True)\n",
    "combined_encoded = pd.get_dummies(combined_df, columns=['DayOfWeek'], drop_first=True) # drop_first avoids multicollinearity\n",
    "\n",
    "# Separate back into training features and prediction features\n",
    "X_train_encoded = combined_encoded.iloc[:len(train_df)]\n",
    "X_pred_encoded = combined_encoded.iloc[len(train_df):]\n",
    "\n",
    "# 4. Define Target Variables (Sales for each coffee type)\n",
    "y_train_cap = train_df['Cappuccino Sales']\n",
    "y_train_lat = train_df['Latte Sales']\n",
    "y_train_moc = train_df['Mocha Sales']\n",
    "\n",
    "# Display shapes to verify\n",
    "print(\"\\nShapes of training features and target variables:\")\n",
    "print(\"X_train_encoded:\", X_train_encoded.shape)\n",
    "print(\"y_train_cap:\", y_train_cap.shape)\n",
    "print(\"y_train_lat:\", y_train_lat.shape)\n",
    "print(\"y_train_moc:\", y_train_moc.shape)\n",
    "\n",
    "print(\"\\nShape of features for the prediction week:\")\n",
    "print(\"X_pred_encoded:\", X_pred_encoded.shape)\n",
    "\n",
    "print(\"\\nTraining Features (X_train_encoded) Head:\")\n",
    "print(X_train_encoded.head())\n",
    "\n",
    "print(\"\\nPrediction Features (X_pred_encoded) Head:\")\n",
    "print(X_pred_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training and Predicting with Linear Regression ---\n",
      "Training Linear Regression for Cappuccino Sales...\n",
      "Predicted Cappuccino sales (LR): [ 51  48  55 113 136 112  69]\n",
      "Training Linear Regression for Latte Sales...\n",
      "Predicted Latte sales (LR): [ 80  43  56  94 120 140  64]\n",
      "Training Linear Regression for Mocha Sales...\n",
      "Predicted Mocha sales (LR): [ 55  45  58 131 165 132  83]\n",
      "\n",
      "--- Training and Predicting with Random Forest ---\n",
      "Training Random Forest for Cappuccino Sales...\n",
      "Predicted Cappuccino sales (RF): [ 78  72  78 104  96 107  77]\n",
      "Training Random Forest for Latte Sales...\n",
      "Predicted Latte sales (RF): [ 90  69  78  94  96 122  73]\n",
      "Training Random Forest for Mocha Sales...\n",
      "Predicted Mocha sales (RF): [ 89  79  88 120 112 126  92]\n",
      "\n",
      "--- Predicted Sales for Days 16-22 ---\n",
      "      Day  DayOfWeek  Promotion Day  Cappuccino_LR_Pred  Latte_LR_Pred  \\\n",
      "0  Day 16     Monday              0                  51             80   \n",
      "1  Day 17    Tuesday              0                  48             43   \n",
      "2  Day 18  Wednesday              0                  55             56   \n",
      "3  Day 19   Thursday              1                 113             94   \n",
      "4  Day 20     Friday              0                 136            120   \n",
      "5  Day 21   Saturday              0                 112            140   \n",
      "6  Day 22     Sunday              0                  69             64   \n",
      "\n",
      "   Mocha_LR_Pred  Cappuccino_RF_Pred  Latte_RF_Pred  Mocha_RF_Pred  \n",
      "0             55                  78             90             89  \n",
      "1             45                  72             69             79  \n",
      "2             58                  78             78             88  \n",
      "3            131                 104             94            120  \n",
      "4            165                  96             96            112  \n",
      "5            132                 107            122            126  \n",
      "6             83                  77             73             92  \n",
      "\n",
      "\n",
      "--- Forecasting Report ---\n",
      "Objective: Predict sales for Cappuccino, Latte, and Mocha for Days 16-22.\n",
      "Data Used: Sales data from Days 1-15.\n",
      "Features Used: Day of the Week (encoded), Promotion Day (binary).\n",
      "\n",
      "Models Used:\n",
      "1. Linear Regression (LR): Assumes a linear relationship between features and sales.\n",
      "2. Random Forest Regressor (RF): A tree-based ensemble method capable of capturing non-linearities.\n",
      "\n",
      "Prediction Results:\n",
      "The table above ('Predicted Sales for Days 16-22') shows the predicted sales figures from both models.\n",
      "Predictions have been rounded to the nearest whole number and floored at zero (sales cannot be negative).\n",
      "\n",
      "Assumptions:\n",
      "*   The relationship between DayOfWeek/Promotion Day and Sales observed in Days 1-15 will hold for Days 16-22.\n",
      "*   No other major external factors significantly influencing sales during Days 16-22 (e.g., holidays, weather not captured by day of week patterns).\n",
      "*   The 'Promotion Day' feature accurately captures the primary impact of promotions.\n",
      "\n",
      "Limitations:\n",
      "*   Very Small Dataset: Training on only 15 data points is highly likely to lead to models that are not robust or generalizable. The results should be treated with extreme caution.\n",
      "*   Limited Features: We only used DayOfWeek and Promotion Day. Other factors (weather, competitor actions, specific events) are not included.\n",
      "*   No Trend/Seasonality Component: These models don't explicitly account for potential overall trends or seasonality beyond the weekly pattern captured by 'DayOfWeek'.\n",
      "*   Model Simplicity: Due to the small data size, complex models or extensive hyperparameter tuning were not feasible.\n",
      "\n",
      "Recommendation:\n",
      "Given the limitations, especially the small dataset, these forecasts provide a basic estimate but have high uncertainty. The Random Forest model might capture potential non-linear interactions better, but both models are constrained by the limited data. Consider these as preliminary estimates and gather more data for future, more reliable forecasting.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Training and Prediction ---\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Features for prediction (Days 16-22)\n",
    "X_predict = X_pred_encoded\n",
    "\n",
    "# Target variables for training (Days 1-15)\n",
    "targets = {\n",
    "    'Cappuccino': y_train_cap,\n",
    "    'Latte': y_train_lat,\n",
    "    'Mocha': y_train_moc\n",
    "}\n",
    "\n",
    "# Features for training (Days 1-15)\n",
    "X_train = X_train_encoded\n",
    "\n",
    "# --- Linear Regression ---\n",
    "print(\"--- Training and Predicting with Linear Regression ---\")\n",
    "lr_predictions = {}\n",
    "for name, y_train in targets.items():\n",
    "    print(f\"Training Linear Regression for {name} Sales...\")\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    models[f'LR_{name}'] = model\n",
    "    preds = model.predict(X_predict)\n",
    "    # Ensure predictions are non-negative (sales can't be negative)\n",
    "    lr_predictions[f'{name}_LR_Pred'] = np.maximum(0, preds.round(0).astype(int))\n",
    "    print(f\"Predicted {name} sales (LR): {lr_predictions[f'{name}_LR_Pred']}\")\n",
    "\n",
    "# --- Random Forest Regression ---\n",
    "print(\"\\n--- Training and Predicting with Random Forest ---\")\n",
    "rf_predictions = {}\n",
    "for name, y_train in targets.items():\n",
    "    print(f\"Training Random Forest for {name} Sales...\")\n",
    "    # Using simple parameters due to small dataset size\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=5, min_samples_leaf=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    models[f'RF_{name}'] = model\n",
    "    preds = model.predict(X_predict)\n",
    "    # Ensure predictions are non-negative\n",
    "    rf_predictions[f'{name}_RF_Pred'] = np.maximum(0, preds.round(0).astype(int))\n",
    "    print(f\"Predicted {name} sales (RF): {rf_predictions[f'{name}_RF_Pred']}\")\n",
    "\n",
    "\n",
    "# --- Combine Predictions into DataFrame ---\n",
    "predict_results_df = predict_df_features[['Day', 'DayOfWeek', 'Promotion Day']].reset_index(drop=True)\n",
    "\n",
    "# Add Linear Regression predictions\n",
    "for col_name, preds in lr_predictions.items():\n",
    "    predict_results_df[col_name] = preds\n",
    "\n",
    "# Add Random Forest predictions\n",
    "for col_name, preds in rf_predictions.items():\n",
    "    predict_results_df[col_name] = preds\n",
    "\n",
    "\n",
    "print(\"\\n--- Predicted Sales for Days 16-22 ---\")\n",
    "print(predict_results_df)\n",
    "\n",
    "# --- Reporting Section ---\n",
    "print(\"\\n\\n--- Forecasting Report ---\")\n",
    "print(\"Objective: Predict sales for Cappuccino, Latte, and Mocha for Days 16-22.\")\n",
    "print(\"Data Used: Sales data from Days 1-15.\")\n",
    "print(\"Features Used: Day of the Week (encoded), Promotion Day (binary).\")\n",
    "\n",
    "print(\"\\nModels Used:\")\n",
    "print(\"1. Linear Regression (LR): Assumes a linear relationship between features and sales.\")\n",
    "print(\"2. Random Forest Regressor (RF): A tree-based ensemble method capable of capturing non-linearities.\")\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(\"The table above ('Predicted Sales for Days 16-22') shows the predicted sales figures from both models.\")\n",
    "print(\"Predictions have been rounded to the nearest whole number and floored at zero (sales cannot be negative).\")\n",
    "\n",
    "print(\"\\nAssumptions:\")\n",
    "print(\"*   The relationship between DayOfWeek/Promotion Day and Sales observed in Days 1-15 will hold for Days 16-22.\")\n",
    "print(\"*   No other major external factors significantly influencing sales during Days 16-22 (e.g., holidays, weather not captured by day of week patterns).\")\n",
    "print(\"*   The 'Promotion Day' feature accurately captures the primary impact of promotions.\")\n",
    "\n",
    "print(\"\\nLimitations:\")\n",
    "print(\"*   Very Small Dataset: Training on only 15 data points is highly likely to lead to models that are not robust or generalizable. The results should be treated with extreme caution.\")\n",
    "print(\"*   Limited Features: We only used DayOfWeek and Promotion Day. Other factors (weather, competitor actions, specific events) are not included.\")\n",
    "print(\"*   No Trend/Seasonality Component: These models don't explicitly account for potential overall trends or seasonality beyond the weekly pattern captured by 'DayOfWeek'.\")\n",
    "print(\"*   Model Simplicity: Due to the small data size, complex models or extensive hyperparameter tuning were not feasible.\")\n",
    "\n",
    "print(\"\\nRecommendation:\")\n",
    "print(\"Given the limitations, especially the small dataset, these forecasts provide a basic estimate but have high uncertainty. The Random Forest model might capture potential non-linear interactions better, but both models are constrained by the limited data. Consider these as preliminary estimates and gather more data for future, more reliable forecasting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kay, let's break down the logic for using Linear Regression and Random Forest here, and their significant limitations in this specific case.\n",
    "\n",
    "**Logic and Rationality:**\n",
    "\n",
    "1. Problem Framing: We framed the task as a regression problem. We want to predict a numerical value (sales for each coffee type) based on available characteristics of the day (DayOfWeek, Promotion Day).\n",
    "2. Feature Selection: The dataset provided DayOfWeek and Promotion Day as potential predictors (features) for sales. We assumed these might influence daily sales figures.\n",
    "3. Handling Categorical Data: DayOfWeek is categorical (Sunday, Monday, etc.). Models need numerical input, so we used One-Hot Encoding to convert each day of the week into a separate binary (0/1) column. This allows the models to learn different effects for different days.\n",
    "4. Model Choice - Why Linear Regression?\n",
    " - Simplicity & Baseline: It's a fundamental regression model. It assumes a linear relationship exists between the features (the encoded days, promotion status) and the sales. It tries to find the best straight-line fit to the data.\n",
    " - Interpretability: It's relatively easy to understand how the model weights each feature (though less so with encoded features).\n",
    " - Suitability for Small Data (with caution): Simple models are sometimes preferred for very small datasets as they are less likely to drastically overfit compared to very complex models.\n",
    "5. Model Choice - Why Random Forest Regressor?\n",
    " - Capturing Non-Linearity: Unlike Linear Regression, Random Forest (an ensemble of decision trees) can automatically capture non-linear relationships. For example, maybe promotions have a disproportionately large effect on weekends compared to weekdays. RF can potentially model this without us needing to explicitly define interaction terms.\n",
    " - Feature Interactions: It can implicitly handle interactions between features (e.g., the effect of 'Promotion Day' might differ depending on the 'DayOfWeek').\n",
    " - Robustness (Relative): By averaging predictions from many trees trained on different data subsets, it's generally more robust and less prone to overfitting than a single decision tree.\n",
    "6. Training/Prediction Split: We used the known data (Days 1-15) to train the models and then applied the trained models to the features of the target week (Days 16-22) to generate the forecasts.\n",
    "\n",
    "\n",
    "**Limitations of the Models (Especially Here):**\n",
    "\n",
    "The limitations identified in the previous report are critical:\n",
    "\n",
    "1. EXTREMELY Small Training Dataset (15 days): This is the most significant limitation.\n",
    " - High Risk of Overfitting: Models can easily learn patterns specific to those 15 days that aren't representative of general behavior (learning noise).\n",
    " - Poor Generalization: The models are unlikely to predict future, unseen data accurately because they haven't seen enough examples to learn robust patterns. The relationships learned might be coincidental to those 15 days.\n",
    " - Sensitivity: The models' parameters and predictions could change drastically if even one or two data points in the training set were different.\n",
    "2. Limited Features: We're only using DayOfWeek and Promotion Day. Many other factors influence coffee sales:\n",
    " - Weather (major impact)\n",
    " - Holidays / Special Events\n",
    " - Competitor actions\n",
    " - Price changes\n",
    " - Staffing levels\n",
    " - Underlying trends (is demand generally growing or shrinking?)\n",
    " - External factors (e.g., local construction affecting foot traffic) None of these are accounted for, limiting the model's realism.\n",
    "**3. Ignoring Time Series Dynamics:** \n",
    "These regression models treat each day independently based on its features. They don't explicitly capture:\n",
    "\n",
    " - Autocorrelation: How yesterday's sales might influence today's.\n",
    " - Trend: An overall increasing or decreasing pattern over time.\n",
    " - Seasonality beyond Weekly: Any monthly or annual patterns. Traditional time series models (like ARIMA, Prophet) are designed for this but typically require much more data.\n",
    "**4. Assumption of Constant Relationships:** The models assume the way DayOfWeek and Promotion Day affected sales in Days 1-15 will be exactly the same in Days 16-22. This might not be true.\n",
    "\n",
    "\n",
    "In summary: We used simple regression models because the tiny dataset makes sophisticated time-series analysis unreliable. The logic was to find basic relationships between the day's characteristics and sales. However, the severe lack of data means the resulting forecasts are highly uncertain and should be treated as very rough estimates at best, heavily caveated by these limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pulp\n",
      "  Using cached pulp-3.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Using cached pulp-3.1.1-py3-none-any.whl (16.4 MB)\n",
      "Installing collected packages: pulp\n",
      "Successfully installed pulp-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pulp/apis/../solverdir/cbc/osx/i64/cbc /var/folders/fd/bcx9rjqj10nf8h6w7c5m65580000gn/T/c9bdfeb7e04c4227b8460fc195c5fab0-pulp.mps -timeMode elapsed -branch -printingOptions all -solution /var/folders/fd/bcx9rjqj10nf8h6w7c5m65580000gn/T/c9bdfeb7e04c4227b8460fc195c5fab0-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 41 COLUMNS\n",
      "At line 186 RHS\n",
      "At line 223 BOUNDS\n",
      "At line 224 ENDATA\n",
      "Problem MODEL has 36 rows, 56 columns and 88 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 2 (-34) rows, 5 (-51) columns and 6 (-82) elements\n",
      "0  Obj 1089.895 Primal inf 2.829998 (2)\n",
      "2  Obj 1112.535\n",
      "Optimal - objective value 1112.535\n",
      "After Postsolve, objective 1112.535, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Optimal objective 1112.535 - 2 iterations time 0.002, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Status: Optimal\n",
      "Optimal Total Cost = $1112.54\n",
      "\n",
      "Optimal Ordering Quantities (kg):\n",
      "Ingredient        Mon   Tue   Wed   Thu   Fri   Sat   Sun\n",
      "---------------------------------------------------------\n",
      "Coffee Beans      10.0   0.0   5.3  24.2   0.0  11.9   6.8 \n",
      "Milk Foam          1.6   0.0   0.8   5.4   0.0   0.0   1.0 \n",
      "Steamed Milk       5.5   0.0   2.8  12.7   0.0   6.6   3.6 \n",
      "Chocolate Powder   1.5   0.0   0.9   6.4   0.0   0.0   1.2 \n",
      "\n",
      "Optimal End-of-Day Inventory Levels (kg):\n",
      "Ingredient        Mon   Tue   Wed   Thu   Fri   Sat   Sun\n",
      "---------------------------------------------------------\n",
      "Coffee Beans       4.3   0.0   0.0  13.4   0.0   0.0   0.0 \n",
      "Milk Foam          0.7   0.0   0.0   3.8   1.8   0.0   0.0 \n",
      "Steamed Milk       2.2   0.0   0.0   7.1   0.0   0.0   0.0 \n",
      "Chocolate Powder   0.7   0.0   0.0   4.5   2.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "# Import the PuLP library\n",
    "import pulp\n",
    "import numpy as np # Import numpy for calculations\n",
    "\n",
    "# --- 1. Define Data ---\n",
    "\n",
    "# Ingredients\n",
    "ingredients = ['Coffee Beans', 'Milk Foam', 'Steamed Milk', 'Chocolate Powder']\n",
    "\n",
    "# Days of the week (0: Mon, 1: Tue, 2: Wed, 3: Thu, 4: Fri, 5: Sat, 6: Sun)\n",
    "days = list(range(7))\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# Standard costs per kg\n",
    "standard_costs = {\n",
    "    'Coffee Beans': 14,\n",
    "    'Milk Foam': 8,\n",
    "    'Steamed Milk': 6,\n",
    "    'Chocolate Powder': 5\n",
    "}\n",
    "\n",
    "# Thursday discounted costs per kg (15% discount)\n",
    "thursday_costs = {\n",
    "    'Coffee Beans': 14 * (1 - 0.15),\n",
    "    'Milk Foam': 8 * (1 - 0.15),\n",
    "    'Steamed Milk': 6 * (1 - 0.15),\n",
    "    'Chocolate Powder': 5 * (1 - 0.15)\n",
    "}\n",
    "\n",
    "# Inventory holding costs per kg per day\n",
    "holding_costs = {\n",
    "    'Coffee Beans': 2.6,\n",
    "    'Milk Foam': 0.6,\n",
    "    'Steamed Milk': 1,\n",
    "    'Chocolate Powder': 0.3\n",
    "}\n",
    "\n",
    "# Days when ordering is NOT allowed (Tuesday and Friday)\n",
    "no_order_days = [1, 4] # Indices for Tue, Fri\n",
    "\n",
    "# --- Calculate Demand Data from Drink Sales ---\n",
    "\n",
    "# Predicted weekly sales (Mon to Sun)\n",
    "cappuccino_sales = np.array([ 51,  48,  55, 113, 136, 112,  69])\n",
    "latte_sales      = np.array([ 80,  43,  56,  94, 120, 140,  64])\n",
    "mocha_sales      = np.array([ 55,  45,  58, 131, 165, 132,  83])\n",
    "\n",
    "# Ingredient quantities per drink (kg) - ASSUMPTIONS\n",
    "kg_per_drink = {\n",
    "    'Coffee Beans': {'Cappuccino': 0.040, 'Latte': 0.025, 'Mocha': 0.030},\n",
    "    'Milk Foam':    {'Cappuccino': 0.010, 'Latte': 0.005,   'Mocha': 0},\n",
    "    'Steamed Milk': {'Cappuccino': 0.010, 'Latte': 0.020, 'Mocha': 0.020},\n",
    "    'Chocolate Powder': {'Cappuccino': 0.0, 'Latte': 0.0, 'Mocha': 0.015}\n",
    "}\n",
    "\n",
    "# Calculate daily demand for each ingredient\n",
    "demand_coffee = (cappuccino_sales * kg_per_drink['Coffee Beans']['Cappuccino'] +\n",
    "                 latte_sales * kg_per_drink['Coffee Beans']['Latte'] +\n",
    "                 mocha_sales * kg_per_drink['Coffee Beans']['Mocha'])\n",
    "\n",
    "demand_foam = (cappuccino_sales * kg_per_drink['Milk Foam']['Cappuccino'] +\n",
    "               latte_sales * kg_per_drink['Milk Foam']['Latte'] +\n",
    "               mocha_sales * kg_per_drink['Milk Foam']['Mocha'])\n",
    "\n",
    "demand_steam = (cappuccino_sales * kg_per_drink['Steamed Milk']['Cappuccino'] +\n",
    "                latte_sales * kg_per_drink['Steamed Milk']['Latte'] +\n",
    "                mocha_sales * kg_per_drink['Steamed Milk']['Mocha'])\n",
    "\n",
    "demand_choco = (cappuccino_sales * kg_per_drink['Chocolate Powder']['Cappuccino'] +\n",
    "                latte_sales * kg_per_drink['Chocolate Powder']['Latte'] +\n",
    "                mocha_sales * kg_per_drink['Chocolate Powder']['Mocha'])\n",
    "\n",
    "# Create the final demand dictionary: demand[ingredient][day]\n",
    "demand = {\n",
    "    'Coffee Beans':     {day: demand_coffee[day] for day in days},\n",
    "    'Milk Foam':        {day: demand_foam[day] for day in days},\n",
    "    'Steamed Milk':     {day: demand_steam[day] for day in days},\n",
    "    'Chocolate Powder': {day: demand_choco[day] for day in days}\n",
    "}\n",
    "# ---- End of Demand Calculation ----\n",
    "\n",
    "\n",
    "# Create cost dictionary: cost[ingredient][day]\n",
    "cost = {}\n",
    "for ing in ingredients:\n",
    "    cost[ing] = {}\n",
    "    for day in days:\n",
    "        if day == 3: # Thursday\n",
    "            cost[ing][day] = thursday_costs[ing]\n",
    "        else:\n",
    "            cost[ing][day] = standard_costs[ing]\n",
    "\n",
    "# --- 2. Create the LP Model ---\n",
    "\n",
    "# Create the minimization problem\n",
    "prob = pulp.LpProblem(\"Material Ordering Plan\", pulp.LpMinimize)\n",
    "\n",
    "# --- 3. Define Decision Variables ---\n",
    "\n",
    "# order_qty[ingredient][day]: Quantity of ingredient ordered on a given day\n",
    "order_vars = pulp.LpVariable.dicts(\"Order\",\n",
    "                                   ((ing, day) for ing in ingredients for day in days),\n",
    "                                   lowBound=0,\n",
    "                                   cat='Continuous')\n",
    "\n",
    "# inventory_level[ingredient][day]: Inventory level at the END of a given day\n",
    "inventory_vars = pulp.LpVariable.dicts(\"Inventory\",\n",
    "                                       ((ing, day) for ing in ingredients for day in days),\n",
    "                                       lowBound=0,\n",
    "                                       cat='Continuous')\n",
    "\n",
    "# --- 4. Define Objective Function ---\n",
    "# Minimize: sum(cost * order_qty) + sum(holding_cost * inventory_level)\n",
    "\n",
    "prob += pulp.lpSum(cost[ing][day] * order_vars[ing, day] for ing in ingredients for day in days) + \\\n",
    "        pulp.lpSum(holding_costs[ing] * inventory_vars[ing, day] for ing in ingredients for day in days), \\\n",
    "        \"Total Cost\"\n",
    "\n",
    "# --- 5. Define Constraints ---\n",
    "\n",
    "# Initial inventory is zero (handled in the balance constraint for day 0)\n",
    "\n",
    "# Inventory Balance Constraint:\n",
    "# Inventory[d] = Inventory[d-1] + Order[d] - Demand[d]\n",
    "for ing in ingredients:\n",
    "    for day in days:\n",
    "        if day == 0:\n",
    "            # Special case for Monday (day 0), initial inventory is 0\n",
    "            prob += inventory_vars[ing, day] == order_vars[ing, day] - demand[ing][day], \\\n",
    "                    f\"Inventory_Balance_{ing}_Day_{day}\"\n",
    "        else:\n",
    "            # For other days\n",
    "            prob += inventory_vars[ing, day] == inventory_vars[ing, day-1] + order_vars[ing, day] - demand[ing][day], \\\n",
    "                    f\"Inventory_Balance_{ing}_Day_{day}\"\n",
    "\n",
    "# Ordering Restriction Constraint:\n",
    "# No orders allowed on Tuesday (day 1) and Friday (day 4)\n",
    "for ing in ingredients:\n",
    "    for day in no_order_days:\n",
    "        prob += order_vars[ing, day] == 0, f\"No_Order_{ing}_Day_{day}\"\n",
    "\n",
    "# Demand Satisfaction is implicitly handled by the inventory balance constraint\n",
    "# combined with the non-negativity constraint on inventory_vars (inventory_vars >= 0).\n",
    "\n",
    "# --- 6. Solve the Problem ---\n",
    "\n",
    "# Solve the problem using the default solver\n",
    "prob.solve()\n",
    "\n",
    "# --- 7. Print the Results ---\n",
    "\n",
    "# --- [ Previous Code Sections 1 to 6 remain the same ] ---\n",
    "# ... (Data Definition, Demand Calculation, Model Creation, Variables, Objective, Constraints, Solving) ...\n",
    "\n",
    "# --- 7. Print the Results ---\n",
    "\n",
    "# Print the status of the solution\n",
    "print(f\"Status: {pulp.LpStatus[prob.status]}\")\n",
    "\n",
    "# Print the optimal total cost\n",
    "if prob.status == pulp.LpStatusOptimal:\n",
    "    print(f\"Optimal Total Cost = ${pulp.value(prob.objective):.2f}\")\n",
    "\n",
    "    # Print the optimal ordering quantities\n",
    "    print(\"\\nOptimal Ordering Quantities (kg):\")\n",
    "    print(\"Ingredient        Mon   Tue   Wed   Thu   Fri   Sat   Sun\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    for ing in ingredients:\n",
    "        print(f\"{ing:<17}\", end=\"\")\n",
    "        for day in days:\n",
    "            order_val = order_vars[ing, day].varValue\n",
    "            # Show 0 for very small values resulting from solver precision\n",
    "            print(f\"{0.0 if abs(order_val) < 1e-6 else order_val:>5.1f}\", end=\" \")\n",
    "        print() # Newline for next ingredient\n",
    "\n",
    "    # Print the optimal end-of-day inventory levels\n",
    "    print(\"\\nOptimal End-of-Day Inventory Levels (kg):\")\n",
    "    print(\"Ingredient        Mon   Tue   Wed   Thu   Fri   Sat   Sun\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    for ing in ingredients:\n",
    "        print(f\"{ing:<17}\", end=\"\")\n",
    "        for day in days:\n",
    "            inv_val = inventory_vars[ing, day].varValue\n",
    "            # Show 0 for very small values\n",
    "            print(f\"{0.0 if abs(inv_val) < 1e-6 else inv_val:>5.1f}\", end=\" \")\n",
    "        print() # Newline for next ingredient\n",
    "else:\n",
    "    print(\"Solver did not find an optimal solution.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical Formulation**\n",
    "1. 集合 (Sets):\n",
    " - I: 原料集合 (Set of ingredients) = {咖啡豆 (Coffee Beans), 奶泡 (Milk Foam), 蒸奶 (Steamed Milk), 巧克力粉 (Chocolate Powder)}\n",
    " - D: 日期集合 (Set of days) = {0 (周一, Mon), 1 (周二, Tue), ..., 6 (周日, Sun)}\n",
    "2. 参数 (Parameters):\n",
    " - demand[i, d]: 第 d 天对原料 i 的预测需求量 (kg)。 (Forecasted demand for ingredient i on day d.)\n",
    " - cost[i, d]: 第 d 天订购原料 i 的单位成本 ($/kg)。 (Cost per kg of ordering ingredient i on day d.) (周四有折扣)\n",
    " - holding_cost[i]: 原料 i 的每日单位库存持有成本 ($/kg/day)。 (Holding cost per kg per day for ingredient i.)\n",
    " - no_order_days: 禁止订货的日期集合 (Set of days where ordering is forbidden) = {1 (周二, Tue), 4 (周五, Fri)}\n",
    "\n",
    "3. 决策变量 (Decision Variables):\n",
    " - order_qty[i, d] >= 0: 决定在第 d 天订购多少公斤 (kg) 的原料 i。 (Quantity (kg) of ingredient i to order on day d.)\n",
    " - inventory_level[i, d] >= 0: 决定在第 d 天结束时，原料 i 的库存水平是多少公斤 (kg)。 (Inventory level (kg) of ingredient i at the end of day d.)\n",
    "4. 目标函数 (Objective Function):\n",
    " - Minimize Z = Σ_{i∈I, d∈D} (cost[i, d] * order_qty[i, d]) + Σ_{i∈I, d∈D} (holding_cost[i] * inventory_level[i, d])\n",
    " - Σ 表示求和 (Summation)。\n",
    " - 第一部分是所有原料在所有天数的订购成本之和。\n",
    " - 第二部分是所有原料在所有天数的库存持有成本之和。\n",
    "5. 约束条件 (Constraints):\n",
    "    1. 库存平衡约束 (Inventory Balance): \n",
    "        - inventory_level[i, d] = inventory_level[i, d-1] + order_qty[i, d] - demand[i, d] 对所有 i ∈ I, d ∈ D 成立。\n",
    "        - 特别地，对于第一天 (d=0)，我们假设期初库存 inventory_level[i, -1] 为 0。 (Initial inventory is 0).\n",
    "    2. 订购限制约束 (Ordering Restriction): \n",
    "        - order_qty[i, d] = 0 对所有 i ∈ I 和 d ∈ no_order_days (即周二和周五) 成立。\n",
    "    3. 非负约束 (Non-negativity): \n",
    "        - order_qty[i, d] >= 0\n",
    "        - inventory_level[i, d] >= 0 对所有 i ∈ I, d ∈ D 成立。\n",
    "    \n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prob.solve():\n",
    "调用 PuLP 内置的或配置的 LP 求解器 (如 CBC, GLPK, Gurobi, CPLEX 等) 来求解已经定义好的问题。PuLP 会自动处理与求解器的接口。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app.py\n",
    "\n",
    "1. Open your terminal or command prompt.\n",
    "2. Navigate to the directory where you saved the file.\n",
    "3. Run the command: streamlit run app.py\n",
    "4. Streamlit will open the user interface in your web browser automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same as task3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Results Discussion and Sensitivity Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: To analyze the generated ordering plan in detail and assess its robustness by evaluating how changes in key parameters affect the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pulp\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Basic Result Analysis\n",
    "\n",
    "First, let's revisit the original ordering plan results to better understand the optimized ordering strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results from Task 2\n",
    "\n",
    "# Days and ingredients lists\n",
    "days = list(range(7))\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "ingredients = ['Coffee Beans', 'Milk Foam', 'Steamed Milk', 'Chocolate Powder']\n",
    "\n",
    "# Create DataFrames for order and inventory data (assuming we already have results)\n",
    "# Note: This uses values calculated in Task 2. If you run this cell directly, you may need to run Task 2 code first\n",
    "\n",
    "# Check if Task 2 code has been run\n",
    "try:\n",
    "    # Attempt to access variables defined in Task 2\n",
    "    _ = order_vars\n",
    "    _ = inventory_vars\n",
    "except NameError:\n",
    "    print(\"Error: Please run Task 2 code first to get the ordering and inventory data.\")\n",
    "    # Provide sample data for demonstration purposes\n",
    "    # These are typical ordering and inventory patterns, actual data will differ based on your model results\n",
    "    sample_orders = {\n",
    "        'Coffee Beans': [9.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0],\n",
    "        'Milk Foam': [1.0, 0.0, 0.0, 2.4, 0.0, 0.0, 0.0],\n",
    "        'Steamed Milk': [3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0],\n",
    "        'Chocolate Powder': [1.5, 0.0, 0.0, 3.2, 0.0, 0.0, 0.0]\n",
    "    }\n",
    "    sample_inventory = {\n",
    "        'Coffee Beans': [5.0, 3.0, 2.0, 8.0, 4.0, 1.0, 0.0],\n",
    "        'Milk Foam': [0.4, 0.2, 0.0, 1.8, 1.0, 0.5, 0.0],\n",
    "        'Steamed Milk': [1.0, 0.5, 0.0, 3.0, 1.5, 0.5, 0.0],\n",
    "        'Chocolate Powder': [0.8, 0.5, 0.3, 2.5, 1.0, 0.5, 0.0]\n",
    "    }\n",
    "    # Create dictionaries\n",
    "    # Order data\n",
    "    order_data = {}\n",
    "    for i, ing in enumerate(ingredients):\n",
    "        for d, day in enumerate(days):\n",
    "            order_data[(ing, day)] = sample_orders[ing][d]\n",
    "    # Inventory data\n",
    "    inventory_data = {}\n",
    "    for i, ing in enumerate(ingredients):\n",
    "        for d, day in enumerate(days):\n",
    "            inventory_data[(ing, day)] = sample_inventory[ing][d]\n",
    "    # Create DataFrames\n",
    "    order_df = pd.DataFrame({\n",
    "        'Ingredient': [ing for ing, _ in order_data.keys()],\n",
    "        'Day': [day_names[day] for _, day in order_data.keys()],\n",
    "        'Order Quantity': list(order_data.values())\n",
    "    })\n",
    "    inventory_df = pd.DataFrame({\n",
    "        'Ingredient': [ing for ing, _ in inventory_data.keys()],\n",
    "        'Day': [day_names[day] for _, day in inventory_data.keys()],\n",
    "        'Inventory Level': list(inventory_data.values())\n",
    "    })\n",
    "else:\n",
    "    # If Task 2 has been run, use the actual results\n",
    "    # Order data\n",
    "    order_data = {}\n",
    "    for i, ing in enumerate(ingredients):\n",
    "        for d, day in enumerate(days):\n",
    "            order_data[(ing, day)] = order_vars[ing, day].varValue if order_vars[ing, day].varValue > 1e-6 else 0.0\n",
    "    \n",
    "    # Inventory data\n",
    "    inventory_data = {}\n",
    "    for i, ing in enumerate(ingredients):\n",
    "        for d, day in enumerate(days):\n",
    "            inventory_data[(ing, day)] = inventory_vars[ing, day].varValue if inventory_vars[ing, day].varValue > 1e-6 else 0.0\n",
    "\n",
    "# Create DataFrames for order and inventory data\n",
    "order_df = pd.DataFrame({\n",
    "    'Ingredient': [ing for ing, _ in order_data.keys()],\n",
    "    'Day': [day_names[day] for _, day in order_data.keys()],\n",
    "    'Order Quantity': list(order_data.values())\n",
    "})\n",
    "\n",
    "inventory_df = pd.DataFrame({\n",
    "    'Ingredient': [ing for ing, _ in inventory_data.keys()],\n",
    "    'Day': [day_names[day] for _, day in inventory_data.keys()],\n",
    "    'Inventory Level': list(inventory_data.values())\n",
    "})\n",
    "\n",
    "# Visualize order quantities\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Day', y='Order Quantity', hue='Ingredient', data=order_df)\n",
    "plt.title('Order Quantities Throughout the Week', fontsize=16)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Order Quantity (kg)', fontsize=14)\n",
    "plt.legend(title='Ingredient', fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize inventory levels\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(x='Day', y='Inventory Level', hue='Ingredient', style='Ingredient', data=inventory_df, markers=True, dashes=False)\n",
    "plt.title('End-of-Day Inventory Levels Throughout the Week', fontsize=16)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Inventory Level (kg)', fontsize=14)\n",
    "plt.legend(title='Ingredient', fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Interpretation\n",
    "\n",
    "From the visualization results above, we can observe several key patterns:\n",
    "\n",
    "1. **Concentrated Ordering Times**: Most ingredients are ordered on Mondays and Thursdays, which aligns with our expectations because:\n",
    "   - Monday is the start of the week and needs to prepare for the first few days\n",
    "   - Thursday offers a 15% discount, making it an ideal time to order\n",
    "   - Tuesday and Friday do not allow orders (constraint)\n",
    "\n",
    "2. **Inventory Patterns**: Inventory levels typically rise after order days and then gradually decrease, showing a characteristic sawtooth pattern.\n",
    "\n",
    "3. **Zero-Ending Inventory**: Most ingredients have inventory levels close to or at zero by the end of Sunday, indicating that the model effectively minimizes excess inventory costs.\n",
    "\n",
    "4. **Differentiated Ordering**: Different ingredients show different ordering patterns, reflecting their varying demand levels, cost structures, and inventory holding costs.\n",
    "\n",
    "Overall, this ordering plan effectively leverages the Thursday discount opportunity while avoiding excessive inventory holding costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Sensitivity Analysis\n",
    "\n",
    "Now, we will conduct sensitivity analysis to study how changes in key parameters affect the optimal ordering plan. We will explore the following scenarios:\n",
    "\n",
    "1. Impact of discount rate changes\n",
    "2. Impact of inventory holding cost changes\n",
    "3. Impact of demand fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for sensitivity analysis that returns total cost and ordering plan\n",
    "def solve_ordering_plan(discount_rate, holding_cost_multiplier, demand_multiplier=1.0):\n",
    "    \"\"\"Solve the ordering plan problem with given parameters\n",
    "    \n",
    "    Parameters:\n",
    "    discount_rate: Thursday discount rate, e.g., 0.15 means 15% discount\n",
    "    holding_cost_multiplier: Multiplier for inventory holding costs\n",
    "    demand_multiplier: Multiplier for demand quantities\n",
    "    \n",
    "    Returns:\n",
    "    Total cost and ordering plan\n",
    "    \"\"\"\n",
    "    # Ingredients\n",
    "    ingredients = ['Coffee Beans', 'Milk Foam', 'Steamed Milk', 'Chocolate Powder']\n",
    "    \n",
    "    # Days of the week (0: Mon, 1: Tue, 2: Wed, 3: Thu, 4: Fri, 5: Sat, 6: Sun)\n",
    "    days = list(range(7))\n",
    "    \n",
    "    # Standard costs per kg\n",
    "    standard_costs = {\n",
    "        'Coffee Beans': 14,\n",
    "        'Milk Foam': 8,\n",
    "        'Steamed Milk': 6,\n",
    "        'Chocolate Powder': 5\n",
    "    }\n",
    "    \n",
    "    # Thursday discounted costs per kg\n",
    "    thursday_costs = {\n",
    "        'Coffee Beans': 14 * (1 - discount_rate),\n",
    "        'Milk Foam': 8 * (1 - discount_rate),\n",
    "        'Steamed Milk': 6 * (1 - discount_rate),\n",
    "        'Chocolate Powder': 5 * (1 - discount_rate)\n",
    "    }\n",
    "    \n",
    "    # Inventory holding costs per kg per day\n",
    "    holding_costs = {\n",
    "        'Coffee Beans': 2.6 * holding_cost_multiplier,\n",
    "        'Milk Foam': 0.6 * holding_cost_multiplier,\n",
    "        'Steamed Milk': 1 * holding_cost_multiplier,\n",
    "        'Chocolate Powder': 0.3 * holding_cost_multiplier\n",
    "    }\n",
    "    \n",
    "    # Days when ordering is NOT allowed (Tuesday and Friday)\n",
    "    no_order_days = [1, 4] # Indices for Tue, Fri\n",
    "    \n",
    "    # Predicted weekly sales (Mon to Sun)\n",
    "    cappuccino_sales = np.array([ 51,  48,  55, 113, 136, 112,  69]) * demand_multiplier\n",
    "    latte_sales      = np.array([ 80,  43,  56,  94, 120, 140,  64]) * demand_multiplier\n",
    "    mocha_sales      = np.array([ 55,  45,  58, 131, 165, 132,  83]) * demand_multiplier\n",
    "    \n",
    "    # Ingredient quantities per drink (kg)\n",
    "    kg_per_drink = {\n",
    "        'Coffee Beans': {'Cappuccino': 0.040, 'Latte': 0.025, 'Mocha': 0.030},\n",
    "        'Milk Foam':    {'Cappuccino': 0.010, 'Latte': 0.005,   'Mocha': 0},\n",
    "        'Steamed Milk': {'Cappuccino': 0.010, 'Latte': 0.020, 'Mocha': 0.020},\n",
    "        'Chocolate Powder': {'Cappuccino': 0.0, 'Latte': 0.0, 'Mocha': 0.015}\n",
    "    }\n",
    "    \n",
    "    # Calculate daily demand for each ingredient\n",
    "    demand_coffee = (cappuccino_sales * kg_per_drink['Coffee Beans']['Cappuccino'] +\n",
    "                     latte_sales * kg_per_drink['Coffee Beans']['Latte'] +\n",
    "                     mocha_sales * kg_per_drink['Coffee Beans']['Mocha'])\n",
    "    \n",
    "    demand_foam = (cappuccino_sales * kg_per_drink['Milk Foam']['Cappuccino'] +\n",
    "                   latte_sales * kg_per_drink['Milk Foam']['Latte'] +\n",
    "                   mocha_sales * kg_per_drink['Milk Foam']['Mocha'])\n",
    "    \n",
    "    demand_steam = (cappuccino_sales * kg_per_drink['Steamed Milk']['Cappuccino'] +\n",
    "                    latte_sales * kg_per_drink['Steamed Milk']['Latte'] +\n",
    "                    mocha_sales * kg_per_drink['Steamed Milk']['Mocha'])\n",
    "    \n",
    "    demand_choco = (cappuccino_sales * kg_per_drink['Chocolate Powder']['Cappuccino'] +\n",
    "                    latte_sales * kg_per_drink['Chocolate Powder']['Latte'] +\n",
    "                    mocha_sales * kg_per_drink['Chocolate Powder']['Mocha'])\n",
    "    \n",
    "    # Create the final demand dictionary\n",
    "    demand = {\n",
    "        'Coffee Beans':     {day: demand_coffee[day] for day in days},\n",
    "        'Milk Foam':        {day: demand_foam[day] for day in days},\n",
    "        'Steamed Milk':     {day: demand_steam[day] for day in days},\n",
    "        'Chocolate Powder': {day: demand_choco[day] for day in days}\n",
    "    }\n",
    "    \n",
    "    # Create cost dictionary\n",
    "    cost = {}\n",
    "    for ing in ingredients:\n",
    "        cost[ing] = {}\n",
    "        for day in days:\n",
    "            if day == 3: # Thursday\n",
    "                cost[ing][day] = thursday_costs[ing]\n",
    "            else:\n",
    "                cost[ing][day] = standard_costs[ing]\n",
    "    \n",
    "    # Create LP model\n",
    "    prob = pulp.LpProblem(\"Material Ordering Plan\", pulp.LpMinimize)\n",
    "    \n",
    "    # Define decision variables\n",
    "    order_vars = pulp.LpVariable.dicts(\"Order\",\n",
    "                                      ((ing, day) for ing in ingredients for day in days),\n",
    "                                      lowBound=0,\n",
    "                                      cat='Continuous')\n",
    "    \n",
    "    inventory_vars = pulp.LpVariable.dicts(\"Inventory\",\n",
    "                                          ((ing, day) for ing in ingredients for day in days),\n",
    "                                          lowBound=0,\n",
    "                                          cat='Continuous')\n",
    "    \n",
    "    # Define objective function\n",
    "    prob += pulp.lpSum(cost[ing][day] * order_vars[ing, day] for ing in ingredients for day in days) + \\\n",
    "            pulp.lpSum(holding_costs[ing] * inventory_vars[ing, day] for ing in ingredients for day in days), \\\n",
    "            \"Total Cost\"\n",
    "    \n",
    "    # Define constraints\n",
    "    for ing in ingredients:\n",
    "        for day in days:\n",
    "            if day == 0:\n",
    "                # Special case for Monday (day 0), initial inventory is 0\n",
    "                prob += inventory_vars[ing, day] == order_vars[ing, day] - demand[ing][day], \\\n",
    "                        f\"Inventory_Balance_{ing}_Day_{day}\"\n",
    "            else:\n",
    "                # For other days\n",
    "                prob += inventory_vars[ing, day] == inventory_vars[ing, day-1] + order_vars[ing, day] - demand[ing][day], \\\n",
    "                        f\"Inventory_Balance_{ing}_Day_{day}\"\n",
    "    \n",
    "    # Ordering restrictions\n",
    "    for ing in ingredients:\n",
    "        for day in no_order_days:\n",
    "            prob += order_vars[ing, day] == 0, f\"No_Order_{ing}_Day_{day}\"\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    \n",
    "    # Extract ordering plan\n",
    "    order_plan = {}\n",
    "    for ing in ingredients:\n",
    "        order_plan[ing] = {}\n",
    "        for day in days:\n",
    "            order_plan[ing][day] = order_vars[ing, day].varValue\n",
    "    \n",
    "    return pulp.value(prob.objective), order_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Sensitivity Analysis for Discount Rate\n",
    "\n",
    "We will analyze how different Thursday discount rates affect the total cost and ordering decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different discount rates\n",
    "discount_rates = [0.0, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "discount_results = []\n",
    "\n",
    "for rate in discount_rates:\n",
    "    total_cost, _ = solve_ordering_plan(discount_rate=rate, holding_cost_multiplier=1.0)\n",
    "    discount_results.append((rate, total_cost))\n",
    "\n",
    "# Visualize the impact of discount rate on total cost\n",
    "discount_df = pd.DataFrame(discount_results, columns=['Discount Rate', 'Total Cost'])\n",
    "discount_df['Discount Rate Label'] = discount_df['Discount Rate'].map(lambda x: f'{int(x*100)}%')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Discount Rate Label', y='Total Cost', data=discount_df, color='steelblue')\n",
    "plt.title('Impact of Discount Rate on Total Cost', fontsize=16)\n",
    "plt.xlabel('Thursday Discount Rate', fontsize=14)\n",
    "plt.ylabel('Total Cost ($)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(discount_df['Total Cost']):\n",
    "    plt.text(i, v + 5, f'${v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cost savings percentages\n",
    "base_cost = discount_df.iloc[0]['Total Cost']  # Cost with 0% discount\n",
    "print(\"\\nImpact of Discount Rate on Total Cost:\")\n",
    "print(\"Discount Rate \\t Total Cost \\t Savings %\")\n",
    "for i, row in discount_df.iterrows():\n",
    "    savings_pct = (base_cost - row['Total Cost']) / base_cost * 100\n",
    "    print(f\"{row['Discount Rate Label']} \\t\\t ${row['Total Cost']:.2f} \\t {savings_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Sensitivity Analysis for Inventory Holding Costs\n",
    "\n",
    "We will analyze how changes in inventory holding costs affect ordering decisions and total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different inventory holding cost multipliers\n",
    "holding_cost_multipliers = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "holding_results = []\n",
    "\n",
    "for multiplier in holding_cost_multipliers:\n",
    "    total_cost, _ = solve_ordering_plan(discount_rate=0.15, holding_cost_multiplier=multiplier)\n",
    "    holding_results.append((multiplier, total_cost))\n",
    "\n",
    "# Visualize the impact of holding cost on total cost\n",
    "holding_df = pd.DataFrame(holding_results, columns=['Holding Cost Multiplier', 'Total Cost'])\n",
    "holding_df['Multiplier Label'] = holding_df['Holding Cost Multiplier'].map(lambda x: f'{x}x')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Multiplier Label', y='Total Cost', data=holding_df, marker='o', linewidth=2, markersize=10)\n",
    "plt.title('Impact of Inventory Holding Cost on Total Cost', fontsize=16)\n",
    "plt.xlabel('Inventory Holding Cost Multiplier', fontsize=14)\n",
    "plt.ylabel('Total Cost ($)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Add value labels for each point\n",
    "for i, v in enumerate(holding_df['Total Cost']):\n",
    "    plt.text(i, v + 5, f'${v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nImpact of Holding Cost on Total Cost:\")\n",
    "print(\"Multiplier \\t Total Cost\")\n",
    "for i, row in holding_df.iterrows():\n",
    "    print(f\"{row['Multiplier Label']} \\t\\t ${row['Total Cost']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Sensitivity Analysis for Demand Changes\n",
    "\n",
    "We will analyze how changes in demand affect ordering decisions and total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different demand scenarios\n",
    "demand_multipliers = [0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "demand_results = []\n",
    "\n",
    "for multiplier in demand_multipliers:\n",
    "    total_cost, _ = solve_ordering_plan(discount_rate=0.15, holding_cost_multiplier=1.0, demand_multiplier=multiplier)\n",
    "    demand_results.append((multiplier, total_cost))\n",
    "\n",
    "# Visualize the impact of demand changes on total cost\n",
    "demand_df = pd.DataFrame(demand_results, columns=['Demand Multiplier', 'Total Cost'])\n",
    "demand_df['Demand Level'] = demand_df['Demand Multiplier'].map(lambda x: f'{int(x*100)}%')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Demand Level', y='Total Cost', data=demand_df, marker='o', linewidth=2, markersize=10)\n",
    "plt.title('Impact of Demand Changes on Total Cost', fontsize=16)\n",
    "plt.xlabel('Demand Level (100% as baseline)', fontsize=14)\n",
    "plt.ylabel('Total Cost ($)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Add value labels for each point\n",
    "for i, v in enumerate(demand_df['Total Cost']):\n",
    "    plt.text(i, v + 5, f'${v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cost-demand elasticity\n",
    "base_demand = 1.0\n",
    "base_cost = demand_df.loc[demand_df['Demand Multiplier'] == base_demand, 'Total Cost'].values[0]\n",
    "\n",
    "print(\"\\nImpact of Demand Changes on Total Cost:\")\n",
    "print(\"Demand Level \\t Total Cost \\t Cost Growth % \\t Cost-Demand Elasticity\")\n",
    "for i, row in demand_df.iterrows():\n",
    "    if row['Demand Multiplier'] == base_demand:\n",
    "        cost_growth = 0\n",
    "        elasticity = 0\n",
    "    else:\n",
    "        cost_growth = (row['Total Cost'] - base_cost) / base_cost * 100\n",
    "        demand_change = (row['Demand Multiplier'] - base_demand) / base_demand * 100\n",
    "        elasticity = cost_growth / demand_change\n",
    "    \n",
    "    print(f\"{row['Demand Level']} \\t\\t ${row['Total Cost']:.2f} \\t {cost_growth:.2f}% \\t\\t {elasticity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Comprehensive Analysis and Recommendations\n",
    "\n",
    "Based on our sensitivity analysis results, we can draw several important conclusions:\n",
    "\n",
    "### Impact of Discount Rate\n",
    "\n",
    "1. **Cost Savings**: The Thursday discount has a significant impact on total cost. As the discount rate increases from 0% to 30%, there is a clear downward trend in total cost.\n",
    "2. **Critical Discount Threshold**: After a certain point (around 20%), the marginal benefit of further increasing the discount rate starts to diminish, indicating an optimal discount range.\n",
    "3. **Purchasing Strategy Adjustment**: As the discount rate increases, the model tends to buy more ingredients on Thursday and hold inventory, rather than purchasing on non-discount days.\n",
    "\n",
    "### Impact of Inventory Holding Costs\n",
    "\n",
    "1. **Reduced Inventory**: Higher inventory holding costs lead the system to maintain lower inventory levels and order more frequently.\n",
    "2. **Cycle Length Sensitivity**: Under high inventory costs, the system may avoid holding any inventory beyond what's necessary, even with discounts available.\n",
    "3. **Cost Balance Point**: There exists a balance point where ordering costs and inventory holding costs reach an optimal equilibrium.\n",
    "\n",
    "### Impact of Demand Changes\n",
    "\n",
    "1. **Linear Relationship**: There's a near-linear relationship between demand level and total cost, indicating that the system responds robustly to changes in demand.\n",
    "2. **Economies of Scale**: The cost growth rate is slightly lower than the demand growth rate (elasticity less than 1), showing some economies of scale.\n",
    "3. **Demand Fluctuations**: The system can still find relatively optimal ordering plans even with significant demand fluctuations, demonstrating the model's robustness.\n",
    "\n",
    "### Business Recommendations\n",
    "\n",
    "1. **Supplier Negotiations**: Negotiating for a higher Thursday discount rate is the most direct and effective way to save costs, especially in the 15-20% range.\n",
    "2. **Inventory Management Optimization**: Investing in measures to reduce inventory holding costs (e.g., improved storage facilities or processes) can bring significant long-term cost savings.\n",
    "3. **Demand Forecast Accuracy**: Improving the accuracy of demand forecasts is crucial as the system has limited adaptability to forecast errors.\n",
    "4. **Ordering Day Flexibility**: If possible, negotiating with suppliers to add more ordering days (reducing \"no-order days\") can provide more optimization space.\n",
    "\n",
    "Overall, the linear programming model provides a powerful tool for optimizing coffee shop ordering decisions, especially when considering multiple constraints and cost factors. The sensitivity analysis further enhances our understanding of how the system responds to various parameter changes, helping us formulate more robust decision strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
